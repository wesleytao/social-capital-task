family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
# result[i,2]<-mse #
result[i,2]<-mim(fit.ela.cv$cvm)
}
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
# result[i,2]<-mse #
result[i,2]<-min(fit.ela.cv$cvm)
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems that lasso tend to perform better than ridge regression. based on the graph We are going to select alpha=0.5
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_test) # get pred over the test set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
# result[i,2]<-min(fit.ela.cv$cvm)
}
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_test) # get pred over the test set
mse        <- mean((y_test - yhat)^2) #compute mse
result[i,2]<-mse #
# result[i,2]<-min(fit.ela.cv$cvm)
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems that lasso tend to perform better than ridge regression. based on the graph We are going to select alpha=0.5
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
library(dplyr)
# combine the data of social capital index with cencus
# head(Census_data)
# head(rate_2014)
rate_2014$id          <- as.integer(rate_2014$id)
Census_data$GEO.id2   <- as.integer(Census_data$GEO.id2)
names(rate_2014)      <-c("GEO.id2","SK14")
newdata<-rate_2014 %>%
left_join(Census_data,by="GEO.id2") # we  are interested in sk2014
setdiff(rate_2014$GEO.id2,Census_data$GEO.id2) # code  2270 46113 are mismatched
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_test) # get pred over the test set
mse        <- mean((y_test - yhat)^2) #compute mse
result[i,2]<-mse #
# result[i,2]<-min(fit.ela.cv$cvm)
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems that lasso tend to perform better than ridge regression. based on the graph We are going to select alpha=0.5
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
# result[i,2]<-min(fit.ela.cv$cvm)
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems that lasso tend to perform better than ridge regression. based on the graph We are going to select alpha=0.5
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
# result[i,2]<-min(fit.ela.cv$cvm)
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems that lasso tend to perform better than ridge regression. based on the graph We are going to select alpha=0.5
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems that lasso tend to perform better than ridge regression. based on the graph We are going to select alpha=0.5
# it seems lasso tend to overfit the problem
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.1se, newx=X_test)
# it seems lasso tend to overfit the problem
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
# it seems lasso tend to overfit the problem
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
# split the data for train and test
# 20% of the data as test data and 80 % as train data
# set.seed(1)
total.num      <-nrow(cleaned_data)
test_index_row <-sample(seq(total.num),total.num*0.2)
train_index_row<-setdiff(seq(total.num),test_index_row)
X_test<-cleaned_data[test_index_row,-1]
y_test<-cleaned_data[test_index_row,1]
X_train<-cleaned_data[train_index_row,-1]
y_train<-cleaned_data[train_index_row,1]
length(test_index_row)+length(train_index_row)==total.num # make sure the number meet
library(ggplot2)
library(reshape2)
cormat       <-round(cor(X_train),2)
melted_cormat<-melt(cormat) # transform to a narrow format
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
# it seems that this data set has a lot of collinearity, It might cause a lot of problem, we need regularization
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# it seems lasso tend to overfit the problem
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
# we are interested in those variabels
data.frame(n=fit.ela.cv$nzero,lambda=fit.ela.cv$lambda)
# we are interested in those variabels
head(data.frame(n=fit.ela.cv$nzero,lambda=fit.ela.cv$lambda),14)
set.seed(1)
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
# we are interested in those variabels
head(data.frame(n=fit.ela.cv$nzero,lambda=fit.ela.cv$lambda),14)
# split the data for train and test
# 20% of the data as test data and 80 % as train data
set.seed(1)
total.num      <-nrow(cleaned_data)
test_index_row <-sample(seq(total.num),total.num*0.2)
train_index_row<-setdiff(seq(total.num),test_index_row)
X_test<-cleaned_data[test_index_row,-1]
y_test<-cleaned_data[test_index_row,1]
X_train<-cleaned_data[train_index_row,-1]
y_train<-cleaned_data[train_index_row,1]
length(test_index_row)+length(train_index_row)==total.num # make sure the number meet
library(ggplot2)
library(reshape2)
cormat       <-round(cor(X_train),2)
melted_cormat<-melt(cormat) # transform to a narrow format
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
# it seems that this data set has a lot of collinearity, It might cause a lot of problem, we need regularization
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
# set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(2)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(1)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
library(ggplot2)
library(reshape2)
cormat       <-round(cor(X_train),2)
melted_cormat<-melt(cormat) # transform to a narrow format
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
# it seems that this data set has a lot of collinearity, It might cause a lot of problem, we need regularization
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(1)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# split the data for train and test
# 20% of the data as test data and 80 % as train data
set.seed(2)
total.num      <-nrow(cleaned_data)
test_index_row <-sample(seq(total.num),total.num*0.2)
train_index_row<-setdiff(seq(total.num),test_index_row)
X_test<-cleaned_data[test_index_row,-1]
y_test<-cleaned_data[test_index_row,1]
X_train<-cleaned_data[train_index_row,-1]
y_train<-cleaned_data[train_index_row,1]
length(test_index_row)+length(train_index_row)==total.num # make sure the number meet
library(ggplot2)
library(reshape2)
cormat       <-round(cor(X_train),2)
melted_cormat<-melt(cormat) # transform to a narrow format
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
# it seems that this data set has a lot of collinearity, It might cause a lot of problem, we need regularization
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(1)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
# split the data for train and test
# 20% of the data as test data and 80 % as train data
set.seed(1)
total.num      <-nrow(cleaned_data)
test_index_row <-sample(seq(total.num),total.num*0.2)
train_index_row<-setdiff(seq(total.num),test_index_row)
X_test<-cleaned_data[test_index_row,-1]
y_test<-cleaned_data[test_index_row,1]
X_train<-cleaned_data[train_index_row,-1]
y_train<-cleaned_data[train_index_row,1]
length(test_index_row)+length(train_index_row)==total.num # make sure the number meet
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(1)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
set.seed(1)
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
# we are interested in those variabels
head(data.frame(n=fit.ela.cv$nzero,lambda=fit.ela.cv$lambda),14)
# use full data
final_model<-glmnet(cleaned_data[,-1], cleaned_data[,1], alpha=0.9, lambda=0.1932824,
family="gaussian")
head(final_model$beta,10) # as we can see many variabel are shrink to seros
myvar<-which(final_model$beta!=0)
final_model$beta
x_names<-colnames(cleaned_data)[-1]
data.frame(code=x_names[myvar],coe=final_model$beta[myvar])
myvar<-which(final_model$beta!=0)
# final_model$beta
x_names<-colnames(cleaned_data)[-1]
data.frame(code=x_names[myvar],coe=final_model$beta[myvar])
dex_index<-which(colnames(var_des) %in% x_names[myvar])
t(var_des[,dex_index])
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data[,c(1,2,3,4,5,6)])
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(1)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(3)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha base on cross-validation error")
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
set.seed(4)
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))# generate a data frame to store the result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=10, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse        <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
# plot mse over alpha
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select Alpha based on cross-validation error")
set.seed(1)
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.9,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
test_mse <- mean((y_test - yhat)^2)
test_mse
# we are interested in those variabels
head(data.frame(n=fit.ela.cv$nzero,lambda=fit.ela.cv$lambda),14)
# use full data
final_model<-glmnet(cleaned_data[,-1], cleaned_data[,1], alpha=0.9, lambda=0.1932824,
family="gaussian")
head(final_model$beta,10) # as we can see many variables are shrink to seros
# use full data
final_model<-glmnet(cleaned_data[,-1], cleaned_data[,1], alpha=0.9, lambda=0.1932824,
family="gaussian")
head(final_model$beta,10) # as we can see many variables are shrink to seros
myvar<-which(final_model$beta!=0)
# final_model$beta
x_names<-colnames(cleaned_data)[-1]
data.frame(code=x_names[myvar],coe=final_model$beta[myvar])
dex_index<-which(colnames(var_des) %in% x_names[myvar])
t(var_des[,dex_index])
data.frame(code=x_names[myvar],coe=final_model$beta[myvar],t(var_des[,dex_index])
data.frame(code=x_names[myvar],coe=final_model$beta[myvar],t(var_des[,dex_index]))
data.frame(code=x_names[myvar],coe=final_model$beta[myvar],t(var_des[,dex_index]))
data.frame(t(var_des[,dex_index]),code=x_names[myvar],coe=final_model$beta[myvar])
dex_index<-which(colnames(var_des) %in% x_names[myvar])
t(var_des[,dex_index])
