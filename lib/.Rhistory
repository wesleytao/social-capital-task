library("xlsx") # load the data
# import the packages we are going to use
library("choroplethr")
library("choroplethrMaps")
table_1997<-read.xlsx("../data/social capital 1997-2014.xlsx", 1)
table_2005<-read.xlsx("../data/social capital 1997-2014.xlsx", 2)
table_2009<-read.xlsx("../data/social capital 1997-2014.xlsx", 3)
table_2014<-read.xlsx("../data/social capital 1997-2014.xlsx", 4)
head(table_2014)# take a look at the head
# plotmap function encapsulate everything
plotmap<-function(df,year){
tempdata<-df[,c(1,3)]
names(tempdata)<-c("region","value")
county_choropleth(tempdata,
title = paste(year, "Social Capital index by county"),
legend="index")
}
# map for 1997
png(filename="1997.png")
plot(faithful)
plotmap(table_1997,"1997")
dev.off()
# plotmap function encapsulate everything
plotmap<-function(df,year){
tempdata<-df[,c(1,3)]
names(tempdata)<-c("region","value")
# save images
setwd("../figs")
png(filename = paste(year,".png",sep = ""))
county_choropleth(tempdata,
title = paste(year, "Social Capital index by county"),
legend="index")
dev.off()
}
# plotmap function encapsulate everything
plotmap<-function(df,year){
tempdata<-df[,c(1,3)]
names(tempdata)<-c("region","value")
# save images
setwd("../figs") # set image path
png(filename = paste(year,".png",sep = ""))
county_choropleth(tempdata,
title = paste(year, "Social Capital index by county"),
legend="index")
dev.off()
}
# map for 1997
plotmap(table_1997,"1997")
# map for 1997
plotmap(table_1997,"1997")
# plotmap function encapsulate everything
plotmap<-function(df,year){
tempdata<-df[,c(1,3)]
names(tempdata)<-c("region","value")
# save images
# setwd("../figs") # set image path
# png(filename = paste(year,".png",sep = ""))
county_choropleth(tempdata,
title = paste(year, "Social Capital index by county"),
legend="index")
# dev.off()
}
# map for 1997
plotmap(table_1997,"1997")
library("xlsx") # load the data
# import the packages we are going to use
library("choroplethr")
library("choroplethrMaps")
table_1997<-read.xlsx("../data/social capital 1997-2014.xlsx", 1)
table_2005<-read.xlsx("../data/social capital 1997-2014.xlsx", 2)
table_2009<-read.xlsx("../data/social capital 1997-2014.xlsx", 3)
table_2014<-read.xlsx("../data/social capital 1997-2014.xlsx", 4)
names(table_1997)
names(table_2005)
# save them in the output for further exploration
# converge them in the same table and save them in csv file for further exploration
new<-merge(x=table_1997,y=table_2005,by.x = "fips",by.y = "fips")
head(new)
names(table_2009)
names(table_2014)
names(table_2005)
names(table_1997)
names(table_2009)
names(table_2014)
names(table_2014)<-c("fips","area_name","sk2014")
library(dplyr)
table_1997 %>%
full_join(table_2005, by = c("fips")) %>%
select(fips, sk97, sk05)
names(table_2014)
names(table_2009)
names(table_2005)
names(table_1997)
# change the header so we could align dataframe
names(table_2014)<-c("fips","area_name","sk14")
m.1<-table_1997 %>%
full_join(table_2005, by = c("fips")) %>%
select(fips, sk97, sk05)
m.2<-table_2009 %>%
full_join(table_2014, by = c("fips")) %>%
select(fips, sk09, sk14)
merged<-m.1 %>%
full_join(table_2005, by = c("fips")) %>%
select(fips, sk97, sk05,sk09,sk14)
merged<-m.1 %>%
full_join(m.2, by = c("fips")) %>%
select(fips, sk97, sk05, sk09, sk14)
head(merged)
nrow(merged)
write.csv(merged,file="../output/merged_4_year.csv")
write.table(merged, file="../output/merged_4_year.csv", quote=FALSE, sep='\t', col.names = NA)
# write.csv(merged,file="../output/merged_4_year.csv")
write.table(merged, file="../output/merged_4_year.tsv", quote=FALSE, sep='\t', col.names = NA)
out_97<-table_1997[,c("fips","sk97")]
names(out_97)<-c("id","rate")
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', col.names = NA)
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', col.names = NA)
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', col.names = NA)
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', col.names = NA)
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_05<-table_2005[,c("fips","sk05")]
names(out_05)<-c("id","rate")
write.table(out_97, file="../output/rate_2005.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_05<-table_2005[,c("fips","sk05")]
names(out_05)<-c("id","rate")
write.table(out_05, file="../output/rate_2005.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_09<-table_2009[,c("fips","sk09")]
names(out_09)<-c("id","rate")
write.table(out_09, file="../output/rate_2009.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_2014<-table_2014[,c("fips","sk14")]
names(out_14)<-c("id","rate")
out_14<-table_2014[,c("fips","sk14")]
names(out_14)<-c("id","rate")
write.table(out_14, file="../output/rate_2014.tsv", quote=FALSE, sep='\t', row.names = FALSE)
library(ggplot2)
ggplot(data=merged,aes(x=sk97))+
geom_histogram()
ggplot(data=merged,aes(x=sk97))+
geom_density()
# plot the histogram
ggplot(data=merged,aes(x=sk97))+
geom_density(apha=0.3)
melt(merged)
library(reshape)
melt(merged)
head(merged)
merged.melt<-melt(merged,id.vars = "fips",variable_name = "year",value.name="index")
head(merged.melt)
merged.melt$year<-as.factor(merged.melt$year)
head(merged.melt)
ggplot(data=merged.melt,aes(x=sk97,fill=year))+
geom_density(apha=0.3)
head(merged.melt)
merged.melt<-melt(merged,id.vars = "fips",variable.name = "year",value.name="index")
merged.melt$year<-as.factor(merged.melt$year)
merged.melt<-melt(merged,id.vars = "fips",variable_name = "year",value_name="index")
merged.melt$year<-as.factor(merged.melt$year)
head(merged.melt)
melt
melt?
?melt
??melt
?melt
library(reshape2)
merged.melt<-melt(merged,id.vars = "fips",variable.name = "year",value.name="index")
merged.melt$year<-as.factor(merged.melt$year)
head(merged.melt)
merged.melt<-melt(merged,id.vars = "fips",variable.name = "year",value.name="index")
ggplot(data=merged.melt,aes(x=value,fill=year))+
geom_density(apha=0.3)
head(merged.melt)
merged.melt<-melt(merged,id.vars = "fips",variable.name = "year",value.name="index")
merged.melt$year<-as.factor(merged.melt$year)
head(merged)
merged.melt<-melt(merged,id.vars = "fips",variable.name = "year",value.name="index")
merged.melt$year<-as.factor(merged.melt$year)
head(merged.melt)
merged.melt<-melt(merged,id.vars = "fips",variable_name = "year",value_name="index")
head(merged.melt)
merged.melt$year<-as.factor(merged.melt$year)
head(merged.melt)
ggplot(data=merged.melt,aes(x=value,fill=year))+
geom_density(apha=0.3)
ggplot(data=merged.melt,aes(x=value,fill=year))+
geom_density(alpha=0.3)
head(merged)
ggplot(data=merged,aes(x=sk97))+
geom_density(alpha=0.3)
ggplot(data=merged,aes(x=sk97))+
geom_histogram()
ggplot(data=merged,aes(x=sk09))+
geom_histogram()
# plotmap function encapsulate everything
plotmap<-function(df,year){
tempdata<-df[,c(1,3)]
names(tempdata)<-c("region","value")
county_choropleth(tempdata,
title = paste(year, "Social Capital index by county"),
legend="index")
}
setwd("../figs") # set image path
png(filename = paste("1997",".png",sep = ""))
plotmap(table_2005,"2005") # map for 2006
dev.off()
setwd("../figs") # set image path
png(filename = paste("2005",".png",sep = ""))
plotmap(table_2005,"2005") # map for 2006
dev.off()
# map for 1997
# save images
setwd("../figs") # set image path
png(filename = paste("1997",".png",sep = ""))
plotmap(table_1997,"1997")
# dev.off()
setwd("../figs") # set image path
png(filename = paste("2009",".png",sep = ""))
plotmap(table_2009,"2009") # map for 2009
# dev.off()
dev.off()
setwd("../figs") # set image path
png(filename = paste("2009",".png",sep = ""))
plotmap(table_2009,"2009") # map for 2009
dev.off()
setwd("../figs") # set image path
png(filename = paste("2014",".png",sep = ""))
plotmap(table_2014,"2014") # map for 2014
dev.off()
head(merged)
head(merged,10)
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
# combine the data of social capital index with cencus
## the key variable GEO.id is incompatible we have to get rid of first 0
Census_data$GEO.id2 <-substr(Census_data$GEO.id2,2,nchar(Census_data$GEO.id2))
head(Cencus_data)
head(Census_data)
head(rate_2014)
head(Census_data)
Census_data$GEO.id2 <-as.integer(Census_data$GEO.id2)
head(rate_2014)
head(Census_data)
names(rate_2014)    <-c("GEO.id2","SK14")
sum(rate_2014$GEO.id2 %in% Census_data$GEO.id2 )
sum(Census_data$GEO.id2 %in%  rate_2014$GEO.id2 )
summary(rate_2014$GEO.id2)
summary(Census_data$GEO.id2)
summary(rate_2014$GEO.id2)
summary(Census_data$GEO.id2)
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
# combine the data of social capital index with cencus
## the key variable GEO.id is incompatible we have to get rid of first 0
Census_data$GEO.id2 <-substr(Census_data$GEO.id2,2,nchar(Census_data$GEO.id2))
head(Census_data)
rate_int     <- as.integer(rate_2014$id)
census_int   <- as.integer(Census_data$GEO.id2)
summary(rate_int)
summary(census_int)
census_int
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
substr("123",1,3)
substr("123",1,1)
substr(Census_data$GEO.id2,1,1)
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
summary(as.integer(Census_data$GEO.id2))
library(dplyr)
# head(rate_2014)
rate_int     <- as.integer(rate_2014$id)
census_int   <- as.integer(Census_data$GEO.id2)
summary(rate_int)
summary(rate_int)
summary(census_int)
# head(rate_2014)
rate_2014$id          <- as.integer(rate_2014$id)
Census_data$GEO.id2   <- as.integer(Census_data$GEO.id2)
names(rate_2014)    <-c("GEO.id2","SK14")
summary(rate_2014$GEO.id2)
summary(Census_data$GEO.id2)
sum(rate_2014$GEO.id2 %in% Census_data$GEO.id2 )
sum(Census_data$GEO.id2 %in%  rate_2014$GEO.id2 )
t
setdiff(rate_2014$GEO.id2,Census_data$GEO.id2)
newdata<-rate_2014 %>%
left_join(Census_data,by="GEO.id2") # we  are interested in sk2014
head(newdata)
# we dig into the cencus data we found that HC03_VC03 is the population
#                                    and HC03_VC(##) is the ## variable divided by population
# therefore we select those variables HC03_VC(##)
names(newdata)
newdata_colnames<-names(newdata)
# we dig into the cencus data we found that HC03_VC03 is the population
#                                    and HC03_VC(##) is the ## variable divided by population
# therefore we select those variables HC03_VC(##)
X_pattern<-"HC03_VC[0-9]"
grep(X_pattern,newdata)
grep(X_pattern,newdata_colnames)
newdata_colnames[X_index]
X_index<-grep(X_pattern,newdata_colnames)
newdata_colnames[X_index]
# we dig into the cencus data we found that HC03_VC03 is the population
#                                    and HC03_VC(##) is the ## variable divided by population
# therefore we select those variables HC03_VC(##)
X_pattern<-"HC03_VC[0-9]+"
newdata_colnames<-names(newdata)
X_index<-grep(X_pattern,newdata_colnames)
head(newdata_colnames[X_index])
X_index
X_index[-1]
X_index<-X_index[-1] # remove the first HC03_VC_03
# split the data for train and test
#
head(newdata)
# split the data for train and test
# 20% of the data as test data and 80 % as train data
head(newdata)
nrow(newdata)
total.num<-nrow(newdata)
seq(total.num)
sample(seq(total.num),total.num*0.2)
test_index <-sample(seq(total.num),total.num*0.2)
train_index<-setdiff(seq(total.num),test_index)
length(test_index)
length(test_index)+length(train_index)
length(test_index)+length(train_index)==total.num
X_train<-newdata[train_index,X_index]
y_train<-newdata[train_index,"SK14"]
library(glmnet)
library(glmnet)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian")
str(y_train)
str(X_train)
# we also find some variables have (X) we have to get rid of them
newdata[,HC03_VC118]
# we also find some variables have (X) we have to get rid of them
head(newdata[,"HC03_VC118"])
as.integer(newdata[,"HC03_VC118"])
as.integer(newdata[,X_index])
head(newdata[,X_index])
apply(head(newdata[,X_index]),2,as.integer)
X_index
head(newdata)
subset_index<-c(y_index,X_index)
y_index<-2
subset_index<-c(y_index,X_index)
newdata.subset<-apply(newdata[,subset_index],2,as.integer)# these '(X)' will be automatically handled by as.integer and replaced by NA
head(newdata.subset)
newdata.subset<-apply(newdata[,subset_index],2,as.numeric)# these '(X)' will be automatically handled by as.integer and replaced by NA
head(newdata.subset)
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean)
?mean
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean(na.rm=T))
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean(na.rm=T))
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean,na.rm=T)
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean,na.rm=T)>200
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean,na.rm=T)<200
newdata.subset[,my_x]
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
my_x<-apply(newdata.subset,2,mean,na.rm=T)<200
heas(newdata.subset[,my_x])
head(newdata.subset[,my_x])
my_x
apply(my_x,1,replace_na)
replace_na<-function(x){
if (is.na(x)==T){return(FALSE)}
else  return (x)
}
apply(my_x,1,replace_na)
apply(my_x,2,replace_na)
tapply(my_x,1,replace_na)
tapply(my_x,2,replace_na)
na.omit(my.x)
na.omit(my_x)
head(newdata.subset[,na.omit(my_x)])
newdata<-newdata.subset[,na.omit(my_x)]
# split the data for train and test
# 20% of the data as test data and 80 % as train data
total.num<-nrow(newdata)
test_index <-sample(seq(total.num),total.num*0.2)
train_index<-setdiff(seq(total.num),test_index)
length(test_index)+length(train_index)==total.num
X_train<-newdata[train_index,X_index]
head(newdata)
my_x[!is.na]
my_x[!is.na(my_x)]
newdata<-newdata.subset[,my_x[!is.na(my_x)]]
head(newdata)
my_x
my_x[!is.na(my_x)]
which(my_x[!is.na(my_x)])
newdata.1<-newdata.subset[,which(my_x[!is.na(my_x)])]
head(newdata.1)
# we also find some variables have (X) we have to get rid of them
head(newdata[,"HC03_VC118"])
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
library(dplyr)
# combine the data of social capital index with cencus
# head(Census_data)
# head(rate_2014)
rate_2014$id          <- as.integer(rate_2014$id)
Census_data$GEO.id2   <- as.integer(Census_data$GEO.id2)
names(rate_2014)      <-c("GEO.id2","SK14")
setdiff(rate_2014$GEO.id2,Census_data$GEO.id2) # geocode  2270 46113 are mismatched
newdata<-rate_2014 %>%
left_join(Census_data,by="GEO.id2") # we  are interested in sk2014
# we dig into the cencus data we found that HC03_VC03 is the population
#                                    and HC03_VC(##) is the ## variable divided by population
# therefore we select those variables HC03_VC(##)
X_pattern       <-"HC03_VC[0-9]+"
newdata_colnames<-names(newdata)
X_index         <-grep(X_pattern,newdata_colnames)
head(newdata_colnames[X_index]) # but HC03_VC_03 is the population
X_index<-X_index[-1] # remove the first HC03_VC_03
y_index<-2
subset_index<-c(y_index,X_index)
C
# we also find some variables have (X) we have to get rid of them
head(newdata[,"HC03_VC118"])
newdata.subset<-apply(newdata[,subset_index],2,as.numeric)# these '(X)' will be automatically handled by as.integer and replaced by NA
head(newdata.subset)
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean,na.rm=T)
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
apply(newdata.subset,2,mean,na.rm=T)<200
which(log.index)
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
log.index<-apply(newdata.subset,2,mean,na.rm=T)<200
which(log.index)
new_index<-which(log.index)
newdata.subset[,new_index]
cleaned_data<-newdata.subset[,new_index]
total.num      <-nrow(cleaned_data)
test_index_row <-sample(seq(total.num),total.num*0.2)
train_index_row<-setdiff(seq(total.num),test_index_row)
length(test_index_row)+length(train_index_row)==total.num
X_train<-newdata[train_index_row,-1]
y_train<-newdata[train_index_row,1]
library(glmnet)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian")
x_train
X_train
head(X_train)
X_train<-cleaned_data[train_index_row,-1]
y_train<-cleaned_data[train_index_row,1]
library(glmnet)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian")
cor(X_train)
?cv.glmnet
options("na.action")
na.action(c(1,2,3))
na.action(c(1,NA,3))
options("na.action")
mean(X_train)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian",na.action=T)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian",na.omit=T)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian",na.omit=T)
na.omit(c(1,NA,3))
