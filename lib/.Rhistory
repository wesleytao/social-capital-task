# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian",na.omit=T)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian",na.omit=T)
na.omit(c(1,NA,3))
Census_data<-read.csv("../data/Census data with variables 2016.csv",header = T,sep=",",as.is = T)
rate_2014  <-read.table("../output/rate_2014.tsv",header=T)
# first row seems to be the description of the variable
var_des    <-Census_data[1,] # store description
Census_data<-Census_data[-1,-1] # rest of the data,drop the first column
head(Census_data)
library(dplyr)
# combine the data of social capital index with cencus
# head(Census_data)
# head(rate_2014)
rate_2014$id          <- as.integer(rate_2014$id)
Census_data$GEO.id2   <- as.integer(Census_data$GEO.id2)
names(rate_2014)      <-c("GEO.id2","SK14")
setdiff(rate_2014$GEO.id2,Census_data$GEO.id2) # geocode  2270 46113 are mismatched
newdata<-rate_2014 %>%
left_join(Census_data,by="GEO.id2") # we  are interested in sk2014
# we dig into the cencus data we found that HC03_VC03 is the population
#                                    and HC03_VC(##) is the ## variable divided by population
# therefore we select those variables HC03_VC(##)
X_pattern       <-"HC03_VC[0-9]+"
newdata_colnames<-names(newdata)
X_index         <-grep(X_pattern,newdata_colnames)
head(newdata_colnames[X_index]) # but HC03_VC_03 is the population
X_index<-X_index[-1] # remove the first HC03_VC_03
y_index<-2
subset_index<-c(y_index,X_index)
# we also find some variables have (X) we have to get rid of them
head(newdata[,"HC03_VC118"])
newdata.subset<-apply(newdata[,subset_index],2,as.numeric)# these '(X)' will be automatically handled by as.integer and replaced by NA
head(newdata.subset)
# it seems that we also have some variables which are population labor force, we have to get rid of them too
# rules are if value is larger than 200 then
log.index<-apply(newdata.subset,2,mean,na.rm=T)<200
new_index<-which(log.index)
cleaned_data<-newdata.subset[,new_index]
cleaned_data<-na.omit(cleaned_data) # omit na by row
# split the data for train and test
# 20% of the data as test data and 80 % as train data
total.num      <-nrow(cleaned_data)
test_index_row <-sample(seq(total.num),total.num*0.2)
train_index_row<-setdiff(seq(total.num),test_index_row)
length(test_index_row)+length(train_index_row)==total.num
X_train<-cleaned_data[train_index_row,-1]
y_train<-cleaned_data[train_index_row,1]
library(glmnet)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=1,
family="gaussian")
summary(fit.lasso.cv)
plot(fit.lasso.cv)
fit.lasso.cv
1
1
X_test<-cleaned_data[test_index_row,-1]
y_test<-cleaned_data[test_index_row,1]
# test data
yhat <- predict(fit.lasso.cv, s=fit.lasso.cv$lambda.1se, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
fit.lasso.cv$lambda.1se
fit.lasso.cv$glmnet.fit
fit.lasso.cv$lambda.min
fit.lasso.cv$name
fit.lasso.cv$cvm
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=1,
family="gaussian")
plot(fit.lasso.cv)
fit.lasso.cv$cvm
# test data
yhat <- predict(fit.lasso.cv, s=fit.lasso.cv$lambda.1se, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
# it seems lasso tend to overfit the problem
fit.ridge.cv <- cv.glmnet(x_train, y_train, type.measure="mse", alpha=0,
family="gaussian")
# it seems lasso tend to overfit the problem
fit.ridge.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0,
family="gaussian")
# it seems lasso tend to overfit the problem
fit.ridge.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0,
family="gaussian",nfolds = 5)
plot(fit.ridge.cv)
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.1se, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
# elastic net
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.5,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
yhat <- predict(fit.ridge.cv, s=fit.ridge.cv$lambda.1se, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
fit.lasso.cv$lambda.min
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.min, newx=X_test)
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.min, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.lse, newx=X_test)
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.lse, newx=X_test)
yhat <- predict(fit.ridge.cv, s=fit.lasso.cv$lambda.1se, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
library(glmnet)
# 10-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
fit.lasso.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=1,
family="gaussian")
plot(fit.lasso.cv)
fit.lasso.cv$lambda
fit.lasso.cv$nzero
cor(X_train)
plot(cor(X_train))
ggcoplot(cor(X_train))
ggcorlot(cor(X_train))
ggcorrplot(cor(X_train))
library(ggplot2)
ggcorrplot(cor(X_train))
library(ggplot2)
library(reshape2)
cormat<-round(cor(X_train),2)
melted_cormat<-melt(cormat)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
fit.lasso.cv$name
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
seq(10)/10
result<-data.frame(rep(NA,2*length(alpha_seq)),ncol=2)
0
result<-data.frame(rep(NA,2*length(alpha_seq)),ncol=2)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
alpha_seq<-seq(10)/10
result<-data.frame(rep(NA,2*length(alpha_seq)),ncol=2)
result
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))
result
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))
# result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
result[i,2]<-fit.lasso.cv$cvm
}
fit.lasso.cv$cvm
fit.lasso.cv$lse
fit.lasso.cv$1se
fit.lasso.cv$ise
fit.lasso.cv$Ise
fit.lasso.cv$lse
fit.lasso.cv$1se
fit.lasso.cv$1se
fit.lasso.cv$1se
fit.lasso.cv$lse
fit.lasso.cv$1se
fit.lasso.cv$1se
fit.lasso.cv$lamda.1se
fit.lasso.cv$lambda.1se
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))
# result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=fit.reg.cv$this.lambda, newx=X_test) # get pred over the train set
mse <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))
# result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_test) # get pred over the train set
mse <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
library(glmnet)
# 5-fold Cross validation for each alpha = 0, 0.1, ... , 0.9, 1.0
alpha_seq<-seq(10)/10
result<-data.frame(alpha=alpha_seq,mse=rep(NA,length(alpha_seq)))
# result
for(i in 1:length(alpha_seq)){
this.alpha <-alpha_seq[i]
fit.reg.cv <- cv.glmnet(X_train, y_train,nfold=5, type.measure="mse", alpha=this.alpha,
family="gaussian")
this.lambda<-fit.reg.cv$lambda.min # we choose lambda with the minimun mse
yhat       <-predict(fit.reg.cv, s=this.lambda, newx=X_train) # get pred over the train set
mse <- mean((y_train - yhat)^2) #compute mse
result[i,2]<-mse #
}
plot(result)
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="cross-validation error: select alpha")
ggplot(data = result,aes(x=alpha,y=mse))+
geom_line()+
labs(title="Select alphaï¼šcross-validation error")
# it seems lasso tend to overfit the problem
fit.ridge.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.5,
family="gaussian",nfolds = 5)
plot(fit.ridge.cv)
# elastic net
fit.ela.cv <- cv.glmnet(X_train, y_train, type.measure="mse", alpha=0.5,
family="gaussian",nfolds = 5)
plot(fit.ela.cv)
# test mse
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.lse, newx=X_test)
# test mse
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.lse, newx=X_test)
plot(fit.ela.cv)
# test mse
fit.ela.cv$lambda.lse
# test mse
fit.ela.cv$lambda.min
# test mse
fit.ela.cv$lambda.1se
# test mse
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
# test mse
yhat <- predict(fit.ela.cv, s=fit.ela.cv$lambda.1se, newx=X_test)
mse <- mean((y_test - yhat)^2)
mse
# we are interested in those variabels
fit.ela.cv$lambda
fit.ela.cv$nzero
# we are interested in those variabels
fit.ela.cv$lambda
# we are interested in those variabels
plot(log(fit.ela.cv$lambda),fit.ela.cv$nzero)
# we are interested in those variabels
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
hline(x=10)
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
vline(x=10)
# we are interested in those variabels
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
abline(x=10)
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
abline(h=10)
# we are interested in those variabels
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
abline(v=10)+
xlab("number of variable selected")+
ylab("lambda")
# we are interested in those variabels
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
abline(v=10)
# xlab("number of variable selected")+
# ylab("lambda")
# we are interested in those variabels
plot(fit.ela.cv$nzero,log(fit.ela.cv$lambda.lse))+
abline(v=10)
# we are interested in those variabels
plot(fit.ela.cv$nzero,fit.ela.cv$lambda.lse)+
abline(v=10)
# xlab("number of variable selected")+
# ylab("lambda")
# we are interested in those variabels
fit.ela.cv$nzero
# we are interested in those variabels
data.frame(n=fit.ela.cv$nzero,lambda=fit.ela.cv$lambda)
glmnet(X_train, y_train, type.measure="mse", alpha=0.5, lambda=0.5360136197,
family="gaussian")
glmnet(X_train, y_train, alpha=0.5, lambda=0.5360136197,
family="gaussian")
final_model<-glmnet(X_train, y_train, alpha=0.5, lambda=0.5360136197,
family="gaussian")
summary(final_model)
final_model$beta
final_model$
final_model$a0
final_model$nobs
final_model$beta
head(final_model$beta)
head(final_model$beta,10)
final_model$beta
class(final_model$beta)
final_model$beta[1]
final_model$beta[2]
final_model$beta[4]
myvar<-final_model$beta!=0
final_model$beta[myvar]
which(myvar)
myvar<-which(final_model$beta!=0)
final_model$beta[myvar]
names(final_model$beta)
final_model$beta
# use full data
final_model<-glmnet(cleaned_data[,-1], cleaned_data[,1], alpha=0.5, lambda=0.5360136197,
family="gaussian")
head(final_model$beta,10) # as we can see many variabel are shrink to seros
myvar<-which(final_model$beta!=0)
final_model$beta
data.frame(myvar,coe=final_model$beta[myvar])
names(cleaned_data)[myvar]
names(cleaned_data)
colnames(cleaned_data)
colnames(cleaned_data)[-1]
data.frame(x_names[myvar],coe=final_model$beta[myvar])
x_names<-colnames(cleaned_data)[-1]
data.frame(code=x_names[myvar],coe=final_model$beta[myvar])
var_des
x_names[myvar] %in% colnames(var_des)
colnames(var_des) %in% x_names[myvar]
colnames(var_des) %in% x_names[myvar]
which(colnames(var_des) %in% x_names[myvar])
dex_index<-which(colnames(var_des) %in% x_names[myvar])
colnames(var_des)[dex_index]
var_des[,dex_index]
var_des[,dex_index].T
var_des[,dex_index]
melt(var_des[,dex_index])
as.vector(var_des[,dex_index])
t(var_des[,dex_index])
t(var_des[,dex_index])[1]
t(var_des[,dex_index])
# import the packages we are going to use
library("xlsx")
library("choroplethr")
library("choroplethrMaps")
# load the data
table_1997<-read.xlsx("../data/social capital 1997-2014.xlsx", 1)
table_2005<-read.xlsx("../data/social capital 1997-2014.xlsx", 2)
table_2009<-read.xlsx("../data/social capital 1997-2014.xlsx", 3)
table_2014<-read.xlsx("../data/social capital 1997-2014.xlsx", 4)
# change the header so we could align dataframe
names(table_2014)<-c("fips","area_name","sk14")
names(table_2009)
names(table_2005)
names(table_1997)
# save them in the output for further exploration
# converge them in the same table and save them in csv file for further exploration
library(dplyr)
m.1<-table_1997 %>%
full_join(table_2005, by = c("fips")) %>%
select(fips, sk97, sk05)
m.2<-table_2009 %>%
full_join(table_2014, by = c("fips")) %>%
select(fips, sk09, sk14)
merged<-m.1 %>%
full_join(m.2, by = c("fips")) %>%
select(fips, sk97, sk05, sk09, sk14)
nrow(merged)
write.csv(merged,file="../output/merged_4_year.csv")# store the whole table
out_97<-table_1997[,c("fips","sk97")]
out_97<-table_1997[,c("fips","sk97")]
names(out_97)<-c("id","rate")
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_05<-table_2005[,c("fips","sk05")]
names(out_05)<-c("id","rate")
write.table(out_05, file="../output/rate_2005.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_09<-table_2009[,c("fips","sk09")]
names(out_09)<-c("id","rate")
write.table(out_09, file="../output/rate_2009.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_14<-table_2014[,c("fips","sk14")]
names(out_14)<-c("id","rate")
write.table(out_14, file="../output/rate_2014.tsv", quote=FALSE, sep='\t', row.names = FALSE)
new<-read.table("../output/rate_2009.tsv")
summary(new)
head(new)
new<-read.table("../output/rate_2009.tsv",header = T)
head(new)
summary(new)
summary(out_5)
summary(out_05)
summary(out_14)
summary(out_14)
6029 %in% out_14$id
6013 %in% out_14$id
out_14$id=6029
out_97<-table_1997[,c("fips","sk97")]
names(out_97)<-c("id","rate")
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_05<-table_2005[,c("fips","sk05")]
names(out_05)<-c("id","rate")
write.table(out_05, file="../output/rate_2005.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_09<-table_2009[,c("fips","sk09")]
names(out_09)<-c("id","rate")
write.table(out_09, file="../output/rate_2009.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_14<-table_2014[,c("fips","sk14")]
names(out_14)<-c("id","rate")
write.table(out_14, file="../output/rate_2014.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_14$id==6029
table_2014[out_14$id==6029,]
out_14[out_14$id==6029,]
table_2014[out_14$id==6029,]
out_14[out_14$id==6029,]
table_2014[out_14$id==6029,]
out_14[out_14$id==6029,]
new<-read.table("../output/rate_2014.tsv",header = T)
new[out_14$id==6029,]
new[out_14$id==32007,]
new[out_14$id==32007,]
table_2014[out_14$id==32007,]
table_2014[out_14$id==6029,]
table_2009[out_14$id==32007,]
table_2009[out_09$id==32007,]
table_2009[out_09$id==6029,]
summary(table_2009)
# import the packages we are going to use
library("xlsx")
library("choroplethr")
library("choroplethrMaps")
# load the data
table_1997<-read.xlsx("../data/social capital 1997-2014.xlsx", 1)
table_2005<-read.xlsx("../data/social capital 1997-2014.xlsx", 2)
table_2009<-read.xlsx("../data/social capital 1997-2014.xlsx", 3)
table_2014<-read.xlsx("../data/social capital 1997-2014.xlsx", 4)
# change the header so we could align dataframe
names(table_2014)<-c("fips","area_name","sk14")
names(table_2009)
names(table_2005)
names(table_1997)
summary(table_1997)
as.string(table_2014$fips)
# load the data
table_1997<-read.xlsx("../data/social capital 1997-2014.xlsx", 1,as.is=T)
as.string(table_1997$fips)
summary(table_1997$fips)
toString(table_1997$fips)
summary(table_1997$fips)
3+"asd"
paste(3+"asd")
paste(as.charater(3)+"asd")
paste(as.character(3)+"asd")
paste(as.character(3),"asd")
paste(as.character(3),"asd",sep="")
convertion<-function(x){
if (x<=9999)
{out=paste("0",as.character(x))
return(out)}
else
return(as.character(x))
}
convertion(992)
# we have to convert 1001 data 01001 because topojson won't match
convertion<-function(x){
if (x<=9999)
{out=paste("0",as.character(x),sep = "")
return(out)}
else
return(as.character(x))
}
convertion(992)
# we have to convert 1001 data 01001 because topojson won't match
convertion<-function(x){
if (x<=9999)
{out=paste("0",as.character(x),sep = "")
return(out)}
else
return(as.character(x))
}
convertion(992)
tapply(table_1997$fips,convertion)
apply(table_1997$fips,1,convertion)
apply(table_1997$fips,2,convertion)
sapply(table_1997$fips,2,convertion)
sapply(table_1997$fips,1,convertion)
tapply(table_1997$fips,1,convertion)
tapply(table_1997$fips,convertion)
tapply(table_1997$fips,mean)
sapply(table_1997$fips,mean)
sapply(table_1997$fips,convertion)
# we have to convert 1001 data 01001 because topojson won't match
convertion<-function(x){
if (x<=9999)
{out=paste("0",as.character(x),sep = "")
return(out)}
else
return(as.character(x))
}
convertion(992)
test<-sapply(table_1997$fips,convertion)
head(test)
tail(test)
#convert them all
table_1997$fips<-sapply(table_1997$fips,convertion)
table_2005$fips<-sapply(table_2005$fips,convertion)
table_2009$fips<-sapply(table_2009$fips,convertion)
table_2014$fips<-sapply(table_2014$fips,convertion)
out_97<-table_1997[,c("fips","sk97")]
names(out_97)<-c("id","rate")
write.table(out_97, file="../output/rate_1997.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_05<-table_2005[,c("fips","sk05")]
names(out_05)<-c("id","rate")
write.table(out_05, file="../output/rate_2005.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_09<-table_2009[,c("fips","sk09")]
names(out_09)<-c("id","rate")
write.table(out_09, file="../output/rate_2009.tsv", quote=FALSE, sep='\t', row.names = FALSE)
out_14<-table_2014[,c("fips","sk14")]
names(out_14)<-c("id","rate")
write.table(out_14, file="../output/rate_2014.tsv", quote=FALSE, sep='\t', row.names = FALSE)
